doc_links <- html %>%
html_nodes("a") %>%
html_attr("href") %>%
grep(pattern = "/u/[0-9]+\\.html", value = TRUE)
# Wenn keine Links gefunden wurden, sind keine weiteren Seiten mehr vorhanden
if (length(doc_links) == 0) {
break
}
# Vollständige URLs erstellen
doc_links <- paste0("https://openjur.de", doc_links)
# Inhalte der gefundenen Links einlesen
for (link in doc_links) {
doc_response <- GET(link)
if (status_code(doc_response) == 200) {
doc_content <- content(doc_response, as = "text")
doc_html <- read_html(doc_content)
# Text aus dem Bereich mit .col-md-9 extrahieren
text_col_md_9 <- doc_html %>%
html_nodes(".col-md-9") %>%
html_text(trim = TRUE)
# Wenn Text vorhanden ist, in das Ergebnis einfügen
if (length(text_col_md_9) > 0) {
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = text_col_md_9, Failed_Link = NA, stringsAsFactors = FALSE))
} else {
# Wenn kein Text vorhanden ist, den Link eintragen
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = NA, Failed_Link = link, stringsAsFactors = FALSE))
}
}
}
# Nächste Seite
page_number <- page_number + 10
} else {
cat("Fehler beim Abrufen der Seite für Keyword:", keyword, "\n")
break
}
}
}
# Ergebnisse anzeigen
print(all_results)
# Liste von unterschiedlichen User-Agents um Web Scraping weniger "auffällig" zu betreiben
user_agents <- c(
"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15",
"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
)
# Basis-URL für die Suchseite
search_url <- "https://openjur.de/suche/"
# Schlüsselwörter
keywords <- c("EA189")
# Ergebnis-Datenrahmen initialisieren
all_results <- data.frame(Keyword = character(), Text = character(), Failed_Link = character(), stringsAsFactors = FALSE)
# Zähler für Anfragen
#request_counter <- 0
for (keyword in keywords) {
page_number <- 0  # Initiale Seitenzahl
while(TRUE) {
# Zufälligen User-Agent auswählen
current_user_agent <- sample(user_agents, 1)
# Anfrage an die Suche mit dem Keyword und der Seitenzahl
response <- GET(paste0(search_url, keyword, "/-ag-vf-vg-bund/", page_number, ".wh-desc.html"))
# Prüfen, ob die Anfrage erfolgreich war
if (status_code(response) == 200) {
# HTML-Inhalt parsen
page_content <- content(response, as = "text")
html <- read_html(page_content)
# Links zu Urteilen extrahieren
doc_links <- html %>%
html_nodes("a") %>%
html_attr("href") %>%
grep(pattern = "/u/[0-9]+\\.html", value = TRUE)
# Wenn keine Links gefunden wurden, sind keine weiteren Seiten mehr vorhanden
if (length(doc_links) == 0) {
break
}
# Vollständige URLs erstellen
doc_links <- paste0("https://openjur.de", doc_links)
# Inhalte der gefundenen Links einlesen
for (link in doc_links) {
doc_response <- GET(link)
if (status_code(doc_response) == 200) {
doc_content <- content(doc_response, as = "text")
doc_html <- read_html(doc_content)
# Text aus dem Bereich mit .col-md-9 extrahieren
text_col_md_9 <- doc_html %>%
html_nodes(".col-md-9") %>%
html_text(trim = TRUE)
# Wenn Text vorhanden ist, in das Ergebnis einfügen
if (length(text_col_md_9) > 0) {
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = text_col_md_9, Failed_Link = NA, stringsAsFactors = FALSE))
} else {
# Wenn kein Text vorhanden ist, den Link eintragen
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = NA, Failed_Link = link, stringsAsFactors = FALSE))
}
}
}
# Nächste Seite
page_number <- page_number + 10
} else {
cat("Fehler beim Abrufen der Seite für Keyword:", keyword, "\n")
break
}
}
}
# Ergebnisse anzeigen
print(all_results)
# Installieren der benötigten Pakete
#install.packages(c("rvest", "httr", "dplyr", "stringr"))
# Laden der Pakete
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(xml2)
library(curl)
# Basis-URL für die Suchseite
search_url <- "https://openjur.de/suche/"
# Schlüsselwörter
keywords <- c("Dieselskandal")
# Ergebnis-Datenrahmen initialisieren
all_results <- data.frame(Keyword = character(), Text = character(), Failed_Link = character(), stringsAsFactors = FALSE)
download_counter <- 0  # Zähler für Downloads
for (keyword in keywords) {
page_number <- 0  # Initiale Seitenzahl
while(TRUE) {
# Anfrage an die Suche mit dem Keyword und der Seitenzahl
response <- GET(paste0(search_url, keyword, "/-ag-vf-vg-bund/", page_number, ".wh-desc.html"))
# Prüfen, ob die Anfrage erfolgreich war
if (status_code(response) == 200) {
# HTML-Inhalt parsen
page_content <- content(response, as = "text")
html <- read_html(page_content)
# Links zu Urteilen extrahieren
doc_links <- html %>%
html_nodes("a") %>%
html_attr("href") %>%
grep(pattern = "/u/[0-9]+\\.html", value = TRUE)
# Wenn keine Links gefunden wurden, sind keine weiteren Seiten mehr vorhanden
if (length(doc_links) == 0) {
cat("Keine weiteren Links gefunden. Möglicherweise ist das Ende der Ergebnisse erreicht.\n")
break
}
# Vollständige URLs erstellen
doc_links <- paste0("https://openjur.de", doc_links)
# Inhalte der gefundenen Links einlesen
for (link in doc_links) {
doc_response <- GET(link)
if (status_code(doc_response) == 200) {
doc_content <- content(doc_response, as = "text")
doc_html <- read_html(doc_content)
# Text aus dem Bereich mit .col-md-9 extrahieren
text_col_md_9 <- doc_html %>%
html_nodes(".col-md-9") %>%
html_text(trim = TRUE)
# Wenn Text vorhanden ist, in das Ergebnis einfügen
if (length(text_col_md_9) > 0) {
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = text_col_md_9, Failed_Link = NA, stringsAsFactors = FALSE))
} else {
# Wenn kein Text vorhanden ist, den Link eintragen
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = NA, Failed_Link = link, stringsAsFactors = FALSE))
}
}
# Download-Zähler erhöhen
download_counter <- download_counter + 1
# Daten speichern, um Speicherplatz zu sparen
if (download_counter %% 100 == 0) {
write.table(all_results, "results_backup.csv", row.names = FALSE, col.names = FALSE, sep = ",", append = TRUE)
all_results <- data.frame(Keyword = character(), Text = character(), Failed_Link = character(), stringsAsFactors = FALSE)
cat("Zwischenspeicherung nach", download_counter, "Downloads abgeschlossen.\n")
}
# Nach 50 Downloads eine Pause einlegen
if (download_counter %% 50 == 0) {
pause_duration <- runif(1, min = 400, max = 600)  # Zufällige Dauer zwischen 40 und 60 Sekunden
cat("Pause von", round(pause_duration, 2), "Sekunden nach", download_counter, "Downloads.\n")
Sys.sleep(pause_duration)
}
}
# Nächste Seite
page_number <- page_number + 10
} else {
cat("Fehler beim Abrufen der Seite:", paste0(search_url, keyword, "/-ag-vf-vg-bund/", page_number, ".wh-desc.html"),
"Status Code:", status_code(response), "\n")
break
}
}
}
# Basis-URL für die Suchseite
search_url <- "https://openjur.de/suche/"
# Schlüsselwörter
keywords <- c("Dieselskandal")
# Ergebnis-Datenrahmen initialisieren
all_results <- data.frame(Keyword = character(), Text = character(), Failed_Link = character(), stringsAsFactors = FALSE)
download_counter <- 0  # Zähler für Downloads
for (keyword in keywords) {
page_number <- 0  # Initiale Seitenzahl
while(TRUE) {
# Anfrage an die Suche mit dem Keyword und der Seitenzahl
response <- GET(paste0(search_url, keyword, "/-ag-vf-vg-bund/", page_number, ".wh-desc.html"))
# Prüfen, ob die Anfrage erfolgreich war
if (status_code(response) == 200) {
# HTML-Inhalt parsen
page_content <- content(response, as = "text")
html <- read_html(page_content)
# Links zu Urteilen extrahieren
doc_links <- html %>%
html_nodes("a") %>%
html_attr("href") %>%
grep(pattern = "/u/[0-9]+\\.html", value = TRUE)
# Wenn keine Links gefunden wurden, sind keine weiteren Seiten mehr vorhanden
if (length(doc_links) == 0) {
cat("Keine weiteren Links gefunden. Möglicherweise ist das Ende der Ergebnisse erreicht.\n")
break
}
# Vollständige URLs erstellen
doc_links <- paste0("https://openjur.de", doc_links)
# Inhalte der gefundenen Links einlesen
for (link in doc_links) {
doc_response <- GET(link)
if (status_code(doc_response) == 200) {
doc_content <- content(doc_response, as = "text")
doc_html <- read_html(doc_content)
# Text aus dem Bereich mit .col-md-9 extrahieren
text_col_md_9 <- doc_html %>%
html_nodes(".col-md-9") %>%
html_text(trim = TRUE)
# Wenn Text vorhanden ist, in das Ergebnis einfügen
if (length(text_col_md_9) > 0) {
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = text_col_md_9, Failed_Link = NA, stringsAsFactors = FALSE))
} else {
# Wenn kein Text vorhanden ist, den Link eintragen
all_results <- rbind(all_results, data.frame(Keyword = keyword, Text = NA, Failed_Link = link, stringsAsFactors = FALSE))
}
}
# Download-Zähler erhöhen
download_counter <- download_counter + 1
# Daten speichern, um Speicherplatz zu sparen
if (download_counter %% 100 == 0) {
write.table(all_results, "results_backup.csv", row.names = FALSE, col.names = FALSE, sep = ",", append = TRUE)
all_results <- data.frame(Keyword = character(), Text = character(), Failed_Link = character(), stringsAsFactors = FALSE)
cat("Zwischenspeicherung nach", download_counter, "Downloads abgeschlossen.\n")
}
# Nach 50 Downloads eine Pause einlegen
if (download_counter %% 50 == 0) {
pause_duration <- runif(1, min = 400, max = 600)  # Zufällige Dauer zwischen 40 und 60 Sekunden
cat("Pause von", round(pause_duration, 2), "Sekunden nach", download_counter, "Downloads.\n")
Sys.sleep(pause_duration)
}
}
# Nächste Seite
page_number <- page_number + 10
} else {
cat("Fehler beim Abrufen der Seite:", paste0(search_url, keyword, "/-ag-vf-vg-bund/", page_number, ".wh-desc.html"),
"Status Code:", status_code(response), "\n")
break
}
}
}
if (!FALSE) {
source("~/scripts/gemini_analysis.R")
perform_analysis()
}
if (FALSE) {
API_KEY = Sys.getenv("API_KEY")
#cat("API_KEY:", substr(API_KEY,1,4))
#system("curl -h")
cat("\n\nSTART TEST ANALYS\n\n")
source("~/scripts/gemini_tools.R")
res = run_gemini("Create a short JSON output about colors.", API_KEY, json_mode=TRUE)
saveRDS(res, "/root/output/result.Rds")
try(writeLines(toJSON(res), "/root/output/result.json"))
cat("\n\nEND TEST ANALYS\n\n")
}
escape_quotes = function(txt, double_quotes=TRUE, single_quotes=TRUE) {
if (single_quotes) {
txt = gsub("'","\\'",txt, fixed=TRUE)
}
if (double_quotes) {
txt = gsub('"','\\"',txt, fixed=TRUE)
}
txt
}
example = function() {
cat(gemini_curl_cmd("Tell a 'joke'","my_key",json_mode = TRUE))
run_gemini("Tell a joke.","my_key",json_mode = TRUE)
}
example = function() {
res = readRDS("C:/libraries/gpt/gemini/result.Rds")
df = gemini_result_to_df(res, artid="myart")
}
gemini_result_to_df = function(res, ...) {
if (!is.null(res$error)) {
li = c(
list(...),
res[c("model","json_mode","temperature")],
list(
error = res$error$message,
finishReason = "error",
content = NA
)
)
} else {
li = c(
list(...),
res[c("model","json_mode","temperature")],
list(
error = "",
finishReason = res$candidates$finishReason[1],
content = paste0(unlist(res$candidates$content,use.names = FALSE), collapse="")
)
)
}
return(as.data.frame(li))
}
run_gemini = function(prompt,api_key, model="gemini-1.5-flash", json_mode=FALSE, temperature=0.1, add_prompt=FALSE, verbose=TRUE) {
library(httr)
library(jsonlite)
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model,":generateContent?key=", api_key)
generationConfig = list(
temperature = temperature
)
if (json_mode) {
generationConfig$response_mime_type = "application/json"
}
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model,":generateContent"),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = list(
list(text = prompt)
)
),
generationConfig = generationConfig
)
)
# Check the status code of the response
status_code = status_code(response)
# Output the content of the response
json = content(response, "text")
if (verbose) {
cat("\n\nResult:\n",nchar(json), " characters:\n\n",json)
}
library(jsonlite)
res = try(fromJSON(json),silent = TRUE)
if (is(res, "try-error")) {
res = list(status_code = status_code,parse_error=TRUE, json=json)
return(res)
}
res$status_code = status_code
res$parse_error = FALSE
if (add_prompt) {
res$prompt = prompt
}
res$model = model
res$json_mode = json_mode
res$temperature = temperature
res
}
run_gemini_embedding = function(text,api_key, model="gemini-1.5-flash",  add_text=FALSE, verbose=TRUE) {
library(httr)
library(jsonlite)
cat("\nCreate embedding:\n")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model,":generateEmbeddings"),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
text = list(text=text)
)
)
)
# Check the status code of the response
status_code = status_code(response)
library(jsonlite)
#cat("\nResponse from creating embedding:\n")
#cat(jsonlite::toJSON(response))
# Output the content of the response
json = content(response, "text")
if (verbose) {
cat("\n\nResult:\n",nchar(json), " characters:\n\n",json)
}
library(jsonlite)
res = try(fromJSON(json),silent = TRUE)
if (is(res, "try-error")) {
res = list(status_code = status_code,parse_error=TRUE, json=json)
return(res)
}
res$status_code = status_code
res$parse_error = FALSE
if (add_prompt) {
res$prompt = prompt
}
res$model = model
res$json_mode = json_mode
res$temperature = temperature
res
}
MAX_RUNTIME_SEC = 5*60*60 # Max runtime on Github
MIN_SEC_PER_PROMPT = 5 # Minimum number of seconds between prompts
perform_analysis = function() {
library(dplyr)
start_time = as.numeric(Sys.time())
API_KEY = Sys.getenv("API_KEY")
setwd("~")
outdir = "/root/output"
if (.Platform$OS.type == "windows") {
setwd("C:/libraries/gpt/gemini/gemini_ex")
}
if (FALSE) {
setwd("~/repbox/gemini/gemini_gha")
}
source("scripts/gemini_tools.R")
config_df = load_prompt_configs()
prompt_files = list.files("prompts", glob2rx("*.txt"),full.names = TRUE)
file = first(prompt_files)
for (file in prompt_files) {
prompt_start_time = as.numeric(Sys.time())
prompt_name = tools::file_path_sans_ext(basename(file))
cat("\n\n****", prompt_name, "***\n")
res = analyse_prompt_file(file, config_df=config_df, api_key = API_KEY)
out_file = paste0(outdir, "/", prompt_name,".Rds")
saveRDS(res, out_file)
cur_time = as.numeric(Sys.time())
# Check total run time
if (cur_time - start_time > MAX_RUNTIME_SEC) {
cat("\nStop because total runtime exceeded ", MAX_RUNTIME_SEC, " seconds.\n")
return()
}
wait_sec = MIN_SEC_PER_PROMPT-(cur_time - prompt_start_time)
if (wait_sec > 0) {
cat("\nWait for ", round(wait_sec), "seconds...")
Sys.sleep(wait_sec)
}
}
cat("\n\nFINISHED\n\n")
}
analyse_prompt_file = function(file, config_df,  api_key,verbose=TRUE, add_prompt=TRUE){
if (verbose) {
cat(paste0("\n\nANALYSE ", file,"\n\n"))
}
prompt = paste0(readLines(file,warn = FALSE), collapse="\n")
config = get_prompt_config(file, config_df)
prompt_name = tools::file_path_sans_ext(basename(file))
if (isTRUE(config$embedding)) {
res = run_gemini_embedding(prompt, api_key,  model=config$model)
} else {
res = run_gemini(prompt, api_key, json_mode=config$json_mode, model=config$model, temperature = config$temperature)
}
res$prompt_name = prompt_name
if (isTRUE(config$add_prompt)) {
res$prompt = prompt
}
res
}
get_prompt_config = function(file, config_df) {
def_config = config_df[config_df$prompt_type=="_default",]
prompt_id = tools::file_path_sans_ext(basename(file))
row = which(prompt_id==config_df$prompt_type)
if (length(row)==0) {
row = which(startsWith(prompt_id, config_df$prompt_type))
}
if (length(row)==0) return(def_config)
config = config_df[row[1],]
fields = names(config)
fields = fields[!sapply(config,is.na)]
def_config[1, fields] = config[1, fields]
def_config[1,]
}
load_prompt_configs = function() {
library(stringi)
library(dplyr)
files = list.files("config",glob2rx("*.yml"),full.names = TRUE)
config_df = bind_rows(lapply(files, function(config_file) {
res = yaml::yaml.load_file(config_file)
prompt_type = tools::file_path_sans_ext(basename(config_file))
res$prompt_type = prompt_type
res = as.data.frame(res)
}))
return(config_df)
}
if (!FALSE) {
source("~/scripts/gemini_analysis.R")
perform_analysis()
}
setwd("~/GitHub/gemini_ex")
if (!FALSE) {
source("~/scripts/gemini_analysis.R")
perform_analysis()
}
setwd("~/GitHub/gemini_ex")
if (!FALSE) {
source("~/scripts/gemini_analysis.R")
perform_analysis()
}
if (!FALSE) {
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R", "r", encoding = "UTF-8")
perform_analysis()
}
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R", "r", encoding = "UTF-8", local = TRUE)
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R", "r", encoding = "UTF-8", local = TRUE, echo = boolesch)
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R", "r", encoding = "UTF-8", local = TRUE, echo = boolean)
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R", "r", encoding = "UTF-8", local = TRUE, echo = bolean)
source("C:/Users/Marnick/Documents/scripts/gemini_analysis.R")
source("~/scripts/gemini_analysis.R")
if (!FALSE) {
source("~/scripts/gemini_analysis.R")
perform_analysis()
}
